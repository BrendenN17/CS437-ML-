{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":364},"executionInfo":{"elapsed":556,"status":"ok","timestamp":1558471774622,"user":{"displayName":"Larry Holder","photoUrl":"https://lh4.googleusercontent.com/-D6NeJUBJ3FI/AAAAAAAAAAI/AAAAAAAAAE4/OTcaA7M4M3U/s64/photo.jpg","userId":"09508083502977978741"},"user_tz":420},"id":"cc8fTGIkJcim","outputId":"92879ae5-0dfe-41d7-a99b-aa9c32233d4b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Tree:\n","  Type == SUV\n","    Color == Red\n","      Stolen: No\n","    Color == Yellow\n","      Origin == Domestic\n","        Stolen: No\n","      Origin == Imported\n","        Stolen: Yes\n","  Type == Sports\n","    Origin == Domestic\n","      Color == Red\n","        Stolen: Yes\n","      Color == Yellow\n","        Stolen: No\n","    Origin == Imported\n","      Stolen: Yes\n","\n","Test instance: ['Red', 'SUV', 'Domestic']\n","  class = No\n"]}],"source":["# Decision tree learning\n","#\n","# Assumes discrete features. Examples may be inconsistent. Stopping condition for tree\n","# generation is when all examples have the same class, or there are no more features\n","# to split on (in which case, use the majority class). If a split yields no examples\n","# for a particular feature value, then the classification is based on the parent's\n","# majority class.\n","\n","import math\n","\n","class TreeNode:\n","    def __init__(self, majClass):\n","        self.split_feature = -1 # -1 indicates leaf node\n","        self.children = {} # dictionary of {feature_value: child_tree_node}\n","        self.majority_class = majClass\n","        \n","def build_tree(examples):\n","    if not examples:\n","        return None\n","    # collect sets of values for each feature index, based on the examples\n","    features = {}\n","    for feature_index in range(len(examples[0]) - 1):\n","        features[feature_index] = set([example[feature_index] for example in examples])\n","    return build_tree_1(examples, features)\n","    \n","def build_tree_1(examples, features):\n","    tree_node = TreeNode(majority_class(examples))\n","    # if examples all have same class, then return leaf node predicting this class\n","    if same_class(examples):\n","        return tree_node\n","    # if no more features to split on, then return leaf node predicting majority class\n","    if not features:\n","        return tree_node\n","    # split on best feature and recursively generate children\n","    best_feature_index = best_feature(features, examples)\n","    tree_node.split_feature = best_feature_index\n","    remaining_features = features.copy()\n","    remaining_features.pop(best_feature_index)\n","    for feature_value in features[best_feature_index]:\n","        split_examples = filter_examples(examples, best_feature_index, feature_value)\n","        tree_node.children[feature_value] = build_tree_1(split_examples, remaining_features)\n","    return tree_node\n","\n","def majority_class(examples):\n","    classes = [example[-1] for example in examples]\n","    return max(set(classes), key = classes.count)\n","\n","def same_class(examples):\n","    classes = [example[-1] for example in examples]\n","    return (len(set(classes)) == 1)\n","\n","def best_feature(features, examples):\n","    # Return index of feature with lowest entropy after split\n","    best_feature_index = -1\n","    best_entropy = 2.0 # max entropy = 1.0\n","    for feature_index in features:\n","        se = split_entropy(feature_index, features, examples)\n","        if se < best_entropy:\n","            best_entropy = se\n","            best_feature_index = feature_index\n","    return best_feature_index\n","\n","def split_entropy(feature_index, features, examples):\n","    # Return weighted sum of entropy of each subset of examples by feature value.\n","    se = 0.0\n","    for feature_value in features[feature_index]:\n","        split_examples = filter_examples(examples, feature_index, feature_value)\n","        se += (float(len(split_examples)) / float(len(examples))) * entropy(split_examples)\n","    return se\n","\n","def entropy(examples):\n","    classes = [example[-1] for example in examples]\n","    classes_set = set(classes)\n","    class_counts = [classes.count(c) for c in classes_set]\n","    e = 0.0\n","    class_sum = sum(class_counts)\n","    for class_count in class_counts:\n","        if class_count > 0:\n","            class_frac = float(class_count) / float(class_sum)\n","            e += (-1.0)* class_frac * math.log(class_frac, 2.0)\n","    return e\n","\n","def filter_examples(examples, feature_index, feature_value):\n","    # Return subset of examples with given value for given feature index.\n","    return list(filter(lambda example: example[feature_index] == feature_value, examples))\n","\n","def print_tree(tree_node, feature_names, depth = 1):\n","    indent_space = depth * \"  \"\n","    if tree_node.split_feature == -1: # leaf node\n","        print(indent_space + feature_names[-1] + \": \" + tree_node.majority_class)\n","    else:\n","        for feature_value in tree_node.children:\n","            print(indent_space + feature_names[tree_node.split_feature] + \" == \" + feature_value)\n","            child_node = tree_node.children[feature_value]\n","            if child_node:\n","                print_tree(child_node, feature_names, depth+1)\n","            else:\n","                # no child node for this value, so use majority class of parent (tree_node)\n","                print(indent_space + \"  \" + feature_names[-1] + \": \" + tree_node.majority_class)\n","\n","def classify(tree_node, instance):\n","    if tree_node.split_feature == -1:\n","        return tree_node.majority_class\n","    child_node = tree_node.children[instance[tree_node.split_feature]]\n","    if child_node:\n","        return classify(child_node, instance)\n","    else:\n","        return tree_node.majority_class\n","\n","if __name__ == \"__main__\":\n","   feature_names = [\"Color\", \"Type\", \"Origin\", \"Stolen\"]\n","   \n","   examples = [\n","       [\"Red\", \"Sports\", \"Domestic\", \"Yes\"],\n","       [\"Red\", \"Sports\", \"Domestic\", \"No\"],\n","       [\"Red\", \"Sports\", \"Domestic\", \"Yes\"],\n","       [\"Yellow\", \"Sports\", \"Domestic\", \"No\"],\n","       [\"Yellow\", \"Sports\", \"Imported\", \"Yes\"],\n","       [\"Yellow\", \"SUV\", \"Imported\", \"No\"],\n","       [\"Yellow\", \"SUV\", \"Imported\", \"Yes\"],\n","       [\"Yellow\", \"SUV\", \"Domestic\", \"No\"],\n","       [\"Red\", \"SUV\", \"Imported\", \"No\"],\n","       [\"Red\", \"Sports\", \"Imported\", \"Yes\"]\n","       ]\n","   tree = build_tree(examples)\n","   print(\"Tree:\")\n","   print_tree(tree, feature_names)\n","   test_instance = [\"Red\", \"SUV\", \"Domestic\"]\n","   test_class = classify(tree, test_instance)\n","   print(\"\\nTest instance: \" + str(test_instance))\n","   print(\"  class = \" + test_class)"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Copy of ML.H1.solution.ipynb","provenance":[{"file_id":"1sSNemafURwN9BOZsVPRnvFP2fevtWse2","timestamp":1611170806854}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.9.10 (main, Jan 15 2022, 11:48:04) \n[Clang 13.0.0 (clang-1300.0.29.3)]"},"metadata":{"interpreter":{"hash":"31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"}},"vscode":{"interpreter":{"hash":"aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"}}},"nbformat":4,"nbformat_minor":0}
